{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naitotomoyuki/YoloLearning_with_ggl_colab/blob/main/yolo12s_Tray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKi9MVg_TPpO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KmD3-tIHYMxN"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ynu65gh9TSUV"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "f438YCUbNO6D"
      },
      "outputs": [],
      "source": [
        "!export LC_ALL=C.UTF-8\n",
        "!export LANG=C.UTF-8\n",
        "!export LANGUAGE=C.UTF-8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 縦横90°切替を学習に混ぜるコールバック ---\n",
        "import torch, random\n",
        "\n",
        "def _rotate_xywh_norm(xywh, k):\n",
        "    x, y, w, h = xywh.unbind(-1)\n",
        "    if k % 4 == 0:      xn, yn, wn, hn = x,       y,       w, h\n",
        "    elif k % 4 == 1:    xn, yn, wn, hn = 1.0 - y, x,       h, w   # +90° CCW\n",
        "    elif k % 4 == 2:    xn, yn, wn, hn = 1.0 - x, 1.0 - y, w, h   # 180°\n",
        "    else:               xn, yn, wn, hn = y,       1.0 - x, h, w   # 270°\n",
        "    return torch.stack([xn, yn, wn, hn], dim=-1)\n",
        "\n",
        "def rotate_batch_90deg_callback(trainer):\n",
        "    # バッチ全体に 90°/270° を p で適用（縦⇄横の切替を学習させる）\n",
        "    p = 0.4\n",
        "    if random.random() > p:\n",
        "        return\n",
        "    b = trainer.batch\n",
        "    imgs = b.get(\"img\", None)\n",
        "    if imgs is None or imgs.ndim != 4:\n",
        "        return\n",
        "    k = random.choice([1, 3])  # 90° or 270°\n",
        "    b[\"img\"] = torch.rot90(imgs, k=k, dims=[-2, -1])\n",
        "    if b.get(\"bboxes\", None) is not None and b[\"bboxes\"].numel() > 0:\n",
        "        b[\"bboxes\"] = _rotate_xywh_norm(b[\"bboxes\"], k)\n",
        "\n",
        "callbacks = {\"on_preprocess_batch\": rotate_batch_90deg_callback}\n"
      ],
      "metadata": {
        "id": "1JOCYMhyp2ts"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqHJgmagKOsm"
      },
      "outputs": [],
      "source": [
        "output_dir = \"runs_experiment\"  # runs_experimentが既に存在している場合削除\n",
        "if os.path.exists(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "    print(f\"✅ ディレクトリ '{output_dir}' を削除しました。\")\n",
        "else:\n",
        "    print(f\"⚠️ ディレクトリ '{output_dir}' は存在しません。\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "pMfiPX77P7d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6cf13fa-c655-4fec-ed18-95c7a34caeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#!pip install -U torch torchvision torchaudio\n",
        "!pip -q install ultralytics==8.3.177 --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "V7XeP7IKKj2j"
      },
      "outputs": [],
      "source": [
        "#!rsync -ah --progress /content/drive/MyDrive/dataset/ /content/dataset/\n",
        "#超重要！！！！！\n",
        "#ローカルPCでdatasetをdataset.zipに圧縮してMyDriveへコピーしてください。\n",
        "\n",
        "# ZIPファイルをGoogle DriveからColabへコピー\n",
        "!rsync -ah --progress /content/drive/MyDrive/dataset.zip /content/\n",
        "\n",
        "# ZIPファイルを解凍\n",
        "!unzip -o /content/dataset.zip -d /content/\n",
        "\n",
        "# (任意) 解凍後のZIPファイルを削除してディスクを節約\n",
        "!rm /content/dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KGcHAX_4i6Z8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68d1e32-8fb5-402c-92ee-69354df8d31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.yaml のパスを更新しました。\n"
          ]
        }
      ],
      "source": [
        "# YAML\n",
        "import yaml\n",
        "\n",
        "# YAMLファイルを読み込む\n",
        "data_yaml = \"/content/dataset/data.yaml\"\n",
        "with open(data_yaml, \"r\") as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "# 変更したいパス\n",
        "data[\"test\"] = \"./images/test\"\n",
        "data[\"train\"] = \"./images/train\"\n",
        "data[\"val\"] = \"./images/val\"\n",
        "\n",
        "# YAMLファイルを書き戻す\n",
        "with open(data_yaml, \"w\") as file:\n",
        "    yaml.safe_dump(data, file, default_flow_style=False)\n",
        "\n",
        "print(\"data.yaml のパスを更新しました。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "U-uMHhBsLWBz"
      },
      "outputs": [],
      "source": [
        "# yolo学習用関数の定義（Colab用）\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "def train_yolo(\n",
        "    model_path,\n",
        "    data_yaml,\n",
        "    epochs=200,\n",
        "    batch_size=16,\n",
        "    img_size=960,\n",
        "    output_dir=\"runs_experiment\",\n",
        "    iou_nms=0.9,\n",
        "    mosaic=0.15,\n",
        "    mixup=0.05,\n",
        "    copy_paste=0.6,\n",
        "    close_mosaic=15,\n",
        "    degrees=0.0, shear=0.0, perspective=0.0, translate=0.05, scale=0.2,\n",
        "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
        "    erasing=0.1, fliplr=0.5, flipud=0.0,\n",
        "    lr0=0.004,\n",
        "    optimizer=\"AdamW\",\n",
        "    cos_lr=True,\n",
        "    warmup_epochs=3,\n",
        "    amp=True,\n",
        "    workers=0,\n",
        "    project_name=\"yolo_project\",\n",
        "    callbacks=callbacks,\n",
        "    **kwargs,                       # ← ここが必須（末尾にカンマも）\n",
        "):\n",
        "    print(f\"Loading model from {model_path}\")\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f\"Training YOLO with {epochs} epochs…\")\n",
        "\n",
        "    model.train(\n",
        "        data=data_yaml,\n",
        "        epochs=epochs,\n",
        "        batch=batch_size,\n",
        "        imgsz=img_size,\n",
        "\n",
        "        # 途中チェックポイントは作らない（save_periodを渡さない）\n",
        "        # save=True のままでOK（best.pt & last.ptは出力される）\n",
        "\n",
        "        # 学習率まわり\n",
        "        optimizer=optimizer,\n",
        "        lr0=lr0,\n",
        "        cos_lr=cos_lr,\n",
        "        warmup_epochs=warmup_epochs,\n",
        "\n",
        "        # Aug/正則化\n",
        "        mosaic=mosaic,\n",
        "        mixup=mixup,\n",
        "        copy_paste=copy_paste,\n",
        "        close_mosaic=close_mosaic,\n",
        "        degrees=degrees,\n",
        "        shear=shear,\n",
        "        perspective=perspective,\n",
        "        translate=translate,\n",
        "        scale=scale,\n",
        "        hsv_h=hsv_h, hsv_s=hsv_s, hsv_v=hsv_v,\n",
        "        erasing=erasing,\n",
        "        fliplr=fliplr,\n",
        "        flipud=flipud,\n",
        "\n",
        "        # 検証時NMS\n",
        "        iou=iou_nms,\n",
        "\n",
        "        # 実行系\n",
        "        amp=amp,\n",
        "        workers=workers,\n",
        "        project=output_dir,\n",
        "        name=project_name,\n",
        "\n",
        "        # 追加パラメータ（cacheやrect、patience等）はここから注入\n",
        "        **kwargs,\n",
        "        # callbacks=callbacks   # ← ここでRandomRotate90適用\n",
        "    )\n",
        "\n",
        "    print(f\"Training complete. Results saved to {output_dir}/{project_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GbNXDl6W6-Y8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ebdfcee-3f78-4cc7-c6ea-890888bf0986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from /content/drive/MyDrive/yolo12s.pt\n",
            "Training YOLO with 200 epochs…\n",
            "New https://pypi.org/project/ultralytics/8.3.178 available 😃 Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=ram, cfg=None, classes=None, close_mosaic=0, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/content/dataset/data.yaml, degrees=10.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.1, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=960, int8=False, iou=0.9, keras=False, kobj=1.0, line_width=None, lr0=0.004, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/yolo12s.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolo_learning4, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs_experiment, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs_experiment/yolo_learning4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.2, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.03, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 4]        \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  2   2689536  ultralytics.nn.modules.block.A2C2f           [512, 512, 2, True, 1]        \n",
            "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 11                  -1  1    345856  ultralytics.nn.modules.block.A2C2f           [768, 256, 1, False, -1]      \n",
            " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 14                  -1  1     95104  ultralytics.nn.modules.block.A2C2f           [512, 128, 1, False, -1]      \n",
            " 15                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1    296704  ultralytics.nn.modules.block.A2C2f           [384, 256, 1, False, -1]      \n",
            " 18                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 21        [14, 17, 20]  1    824052  ultralytics.nn.modules.head.Detect           [12, [128, 256, 512]]         \n",
            "YOLOv12s summary: 272 layers, 9,257,780 parameters, 9,257,764 gradients\n",
            "\n",
            "Transferred 685/691 items from pretrained weights\n",
            "Freezing layer 'model.21.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3878.7±994.9 MB/s, size: 1907.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train.cache... 1179 images, 51 backgrounds, 0 corrupt: 100%|██████████| 1179/1179 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.9GB RAM): 100%|██████████| 1179/1179 [00:07<00:00, 157.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1510.4±1374.3 MB/s, size: 1934.5 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 337 images, 11 backgrounds, 0 corrupt: 100%|██████████| 337/337 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.5GB RAM): 100%|██████████| 337/337 [00:02<00:00, 130.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs_experiment/yolo_learning4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.004, momentum=0.937) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
            "Image sizes 960 train, 960 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns_experiment/yolo_learning4\u001b[0m\n",
            "Starting training for 200 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 676.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 896.00 KiB is free. Process 4261 has 39.54 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 358.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1711206007.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# ====== 実行 ======\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtrain_yolo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3391547925.py\u001b[0m in \u001b[0;36mtrain_yolo\u001b[0;34m(model_path, data_yaml, epochs, batch_size, img_size, output_dir, iou_nms, mosaic, mixup, copy_paste, close_mosaic, degrees, shear, perspective, translate, scale, hsv_h, hsv_s, hsv_v, erasing, fliplr, flipud, lr0, optimizer, cos_lr, warmup_epochs, amp, workers, project_name, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training YOLO with {epochs} epochs…\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     model.train(\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_yaml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mpreprocess_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPreprocessed\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnormalized\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_scale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 676.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 896.00 KiB is free. Process 4261 has 39.54 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 358.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "# ====== 設定 ======\n",
        "model_path = \"/content/drive/MyDrive/yolo12s.pt\"  # 初回学習\n",
        "# model_path = \"/content/drive/MyDrive/20250801iFujicco_item_yolo12m.pt\"  # 継続学習の場合\n",
        "\n",
        "data_yaml = \"/content/dataset/data.yaml\"\n",
        "project_name = \"yolo_learning\"\n",
        "\n",
        "train_params = {\n",
        "    \"model_path\": model_path,\n",
        "    \"data_yaml\": data_yaml,\n",
        "    \"epochs\": 200,\n",
        "    \"batch_size\": 64,\n",
        "    \"lr0\": 0.004,\n",
        "    \"img_size\": 960,\n",
        "    \"output_dir\": \"runs_experiment\",\n",
        "    \"cache\": \"ram\",\n",
        "    \"rect\": False,\n",
        "    \"iou_nms\": 0.90,\n",
        "    \"mosaic\": 0.0,\n",
        "    \"mixup\": 0.0,\n",
        "    \"copy_paste\": 0.0,\n",
        "    \"close_mosaic\": 0,\n",
        "    \"degrees\": 10.0,\n",
        "    \"shear\": 0.0,\n",
        "    \"perspective\": 0.0,\n",
        "    \"translate\": 0.03,\n",
        "    \"scale\": 0.2,\n",
        "    \"hsv_h\": 0.015,\n",
        "    \"hsv_s\": 0.7,\n",
        "    \"hsv_v\": 0.4,\n",
        "    \"erasing\": 0.1,\n",
        "    \"fliplr\": 0.5,\n",
        "    \"flipud\": 0.5,\n",
        "    \"lr0\": 0.004,\n",
        "    \"optimizer\": \"AdamW\",\n",
        "    \"cos_lr\": True,\n",
        "    \"warmup_epochs\": 3,\n",
        "    \"amp\": True,\n",
        "    \"workers\": 2,\n",
        "    \"project_name\": project_name,\n",
        "    # \"callbacks\": callbacks # Callbacks are not a valid argument in this version\n",
        "}\n",
        "\n",
        "# ====== 実行 ======\n",
        "train_yolo(**train_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqP5hOwPYQml"
      },
      "outputs": [],
      "source": [
        "output_dir = \"runs_experiment\"\n",
        "best_model_path = f\"{output_dir}/{project_name}/weights/best.pt\"\n",
        "last_model_path = f\"{output_dir}/{project_name}/weights/last.pt\"\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "for model_path in [best_model_path, last_model_path]:\n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"Downloading: {model_path}\")\n",
        "        files.download(model_path)\n",
        "    else:\n",
        "        print(f\"[ERROR] {os.path.basename(model_path)} が見つかりません: {model_path}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}